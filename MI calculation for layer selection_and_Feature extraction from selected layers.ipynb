{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8kW5gmfj0JL"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#import the network\n",
        "from keras.applications import DenseNet169"
      ],
      "metadata": {
        "id": "eQW6j9htj1x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.svm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "DuzSQRTEl3PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "hSonTcYcsQHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = DenseNet169(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "L5XP-iqqj104"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "id": "hQOZS-Puj13g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive with colab to import the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XRTj_NZnj162"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "h6ZHhi2ykVkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir=\"/content/drive/MyDrive/BC_dataset/M400\""
      ],
      "metadata": {
        "id": "OqDhe9LukVm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "  main_dir,\n",
        "  validation_split= None,\n",
        "  subset= None,\n",
        "  shuffle=False,\n",
        "  seed=None,\n",
        "  image_size=(224, 224),\n",
        "  batch_size=32)"
      ],
      "metadata": {
        "id": "AADvWkJpkVqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "nJJLnCuBlK4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "GiEp_YrmlK7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature extraction (baseline)\n",
        "#change the preprocessing part based on the network\n",
        "def extract_features(data):\n",
        "  all_features  = []\n",
        "  all_labels  = []\n",
        "  for images, labels in data:\n",
        "    preprocessed_img  = tf.keras.applications.densenet.preprocess_input(images)\n",
        "    features  = conv_base.predict(preprocessed_img)\n",
        "    all_features.append(features)\n",
        "    all_labels.append(labels)\n",
        "  return np.concatenate(all_features) , np.concatenate(all_labels)"
      ],
      "metadata": {
        "id": "gQMySXBslK9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels= extract_features(dataset)"
      ],
      "metadata": {
        "id": "y0YEUPfylLAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features= train_features.reshape(1820, -1 )"
      ],
      "metadata": {
        "id": "9tpoK8lPl3Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification with baseline features\n",
        "K=10\n",
        "# Initialize lists to store the metrics for each iteration\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "roc_aucs = []\n",
        "scores = []\n",
        "for i in range(K):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.20,random_state=42+i)\n",
        "  SVM = sklearn.svm.SVC(kernel='rbf',C=5)\n",
        "  classifier=SVM.fit(x_train, y_train)\n",
        "  s=SVM.score(x_test, y_test)\n",
        "  y_pred = SVM.predict(x_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "  accuracies.append(accuracy)\n",
        "  precisions.append(precision)\n",
        "  recalls.append(recall)\n",
        "  f1_scores.append(f1)\n",
        "\n",
        "  print(i,'\\n ')\n",
        "  print('prediction = ',y_pred)\n",
        "  print('GroundTruth = ', y_test)\n",
        "  print('length of xtest', len(x_test))\n",
        "  print(\"The score for this classification is: \", s)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  scores.append(s)\n",
        "print(\"The mean and standard deviation of classification  is :\", np.mean(scores), np.std(scores))\n",
        "print(\"max  = \",max(scores),\"min  = \",min(scores))\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average Accuracy: {avg_accuracy:.4f}', \"std= \", np.std(accuracies))\n",
        "print(f'Average Precision: {avg_precision:.4f}', \"std= \", np.std(precisions) )\n",
        "print(f'Average Recall: {avg_recall:.4f}',  \"std= \", np.std(recalls) )\n",
        "print(f'Average F1 Score: {avg_f1_score:.4f}',  \"std= \",np.std(f1_scores) )\n"
      ],
      "metadata": {
        "id": "RE16_4_XsQX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPIjI-sVv4fD"
      },
      "outputs": [],
      "source": [
        "#feature extraction from middle layers\n",
        "#change the preprocessing part based on the network\n",
        "def extract_features_middlelayers(data,layer_name):\n",
        "   all_features  = []\n",
        "   all_labels  = []\n",
        "   intermediate_layer  = conv_base.get_layer(layer_name)\n",
        "   intermediate_model  = Model(inputs = conv_base.inputs, outputs  = intermediate_layer.output)\n",
        "   for images, labels in data:\n",
        "      preprocessed_img  = tf.keras.applications.densenet.preprocess_input(images)\n",
        "      intermediate_output = intermediate_model.predict(preprocessed_img)\n",
        "      all_features.append(intermediate_output)\n",
        "      all_labels.append(labels)\n",
        "\n",
        "\n",
        "   return np.concatenate(all_features) , np.concatenate(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0f0C86Iv4k3"
      },
      "outputs": [],
      "source": [
        "#extract features from a specific layer based on its name (from network's summary)\n",
        "train_features_S3B2C, train_labels_S3B2C= extract_features_middlelayers(data=dataset,layer_name=\"convnext_tiny_stage_3_block_2_depthwise_conv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DO9rvAZLlDR"
      },
      "outputs": [],
      "source": [
        "train_features_S3B2C=train_features_S3B2C.reshape(1820,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaAy3w5zv4rd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYqO3-y1Y1xY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS3yRZCgv4zk"
      },
      "outputs": [],
      "source": [
        "train_features_S3B2C = pd.DataFrame(train_features_S3B2C)\n",
        "train_labels_S3B2C =  pd.DataFrame(train_labels_S3B2C)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mi_scores(X, y):\n",
        "    mi_scores = mutual_info_classif(X,y)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores"
      ],
      "metadata": {
        "id": "-ry16sXYWsqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate Mutual Information\n",
        "mi_scorce_S3B2C= make_mi_scores(train_features_S3B2C, train_labels_S3B2C)"
      ],
      "metadata": {
        "id": "pLgIbnIeWstI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(mi_scorce_S3B2C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNMXKDSuWsvg",
        "outputId": "b24425c5-ef33-4a45-a4f5-8083247cc941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07791213456427082"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.svm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "U71ydYAkWsyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jn65-VIkYihV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "jOGTDoyKYijv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=20)"
      ],
      "metadata": {
        "id": "FImyR0AHYimx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA on features from selected layers"
      ],
      "metadata": {
        "id": "YYUoEsWD0bIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(svd_solver='full').fit(train_features_S3B2C)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "vEUrjVegYq6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "train_features_S3B2C=sc.fit_transform(train_features_S3B2C)\n",
        "pca = PCA(svd_solver='full').fit(train_features_S3B2C)"
      ],
      "metadata": {
        "id": "SFgFLwmOYq8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "sum=(pca.explained_variance_ratio_.cumsum())\n",
        "print(sum)"
      ],
      "metadata": {
        "id": "I56YvgJ2YrAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.where(sum>=0.05)\n",
        "n_component=(indices[0][0])\n",
        "print(n_component)"
      ],
      "metadata": {
        "id": "Iuw_oowOY6ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "K=10\n",
        "#change CEV to find the optimum\n",
        "CV_vec = range(5,105,5)\n",
        "scores_no_pca = []\n",
        "scores_pca = np.zeros((K,len(CV_vec)), dtype=float)\n",
        "for i in range(K):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(train_features_S3B2C, train_labels_S3B2C, test_size=0.20,random_state=42+i)\n",
        "\n",
        "  for idx,cv in enumerate(CV_vec):\n",
        "    try:\n",
        "       indices = np.where(sum >= cv/100.0)\n",
        "       n_component=(indices[0][0])\n",
        "    except:\n",
        "       n_component=len(sum)\n",
        "\n",
        "    pca=PCA(n_components=n_component, svd_solver='full')\n",
        "\n",
        "    SVM = sklearn.svm.SVC(kernel='rbf',C=5)\n",
        "    try:\n",
        "      x_train_pca=pca.fit_transform(x_train)\n",
        "    except:\n",
        "      pca=PCA(n_components=len(y_train), svd_solver='full')\n",
        "      x_train_pca=pca.fit_transform(x_train)\n",
        "\n",
        "    x_test_pca=pca.transform(x_test)\n",
        "    classifier=SVM.fit(x_train_pca, y_train)\n",
        "    s1=SVM.score(x_test_pca, y_test)\n",
        "    y_pred1 = SVM.predict(x_test_pca)\n",
        "\n",
        "    print('cv=', cv,'\\n ')\n",
        "    print(i,'\\n ')\n",
        "    print('prediction = ',y_pred1)\n",
        "    print('GroundTruth = ', y_test)\n",
        "    print('length of xtest', len(x_test))\n",
        "    print(\"The score for this classification is: \", s1)\n",
        "    print(\"#component = \",n_component)\n",
        "    scores_pca[i][idx] = s1\n",
        "print(\"The mean and standard deviation of classification with pca is :\", np.mean(scores_pca), np.std(scores_pca))"
      ],
      "metadata": {
        "id": "UtIIb5rHZV-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_pca_pd=pd.DataFrame(data=scores_pca)\n",
        "scores_pca_pd.rename(columns={x:y for x,y in zip(scores_pca_pd.columns,range(5,105,5))},inplace=True)\n",
        "scores_pca_pd"
      ],
      "metadata": {
        "id": "5ukoKop8Ki7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=)\n",
        "pca.fit(train_features_S3B2C)\n",
        "train_features_S3B2C = pca.transform(train_features_S3B2C)"
      ],
      "metadata": {
        "id": "AmRuF8Se0YKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save features (considering a specific CEV) as a CSV file\n",
        "pd.DataFrame(train_features_S3B2C).to_csv('/content/drive/MyDrive/features and labels/S3B2C.csv', index=False)"
      ],
      "metadata": {
        "id": "dIO6VDF81YPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}